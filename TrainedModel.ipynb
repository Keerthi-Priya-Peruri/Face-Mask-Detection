{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_ksCCw6pE_e"
      },
      "outputs": [],
      "source": [
        "import cv2 # computer vision :for various image and video processing tasks.\n",
        "# It's commonly used for tasks like image manipulation, object detection, face recognition, and more.\n",
        "\n",
        "from tensorflow.keras.models import Sequential # essential for building a sequential neural network model in Keras.\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense\n",
        "# Conv2D is used for convolutional operations, which are fundamental in CNNs for extracting features from images.\n",
        "# MaxPooling2D is used for downsampling the spatial dimensions of the input.It helps reduce the computational complexity and control overfitting by retaining the most important information.\n",
        "# Dropout used to prevent overfitting by randomly setting a fraction of input units to 0 at each update during training.\n",
        "# Flatten is used to reshape the data from a multi-dimensional tensor into a 1D array\n",
        "# Dense represents a fully connected layer, where each neuron is connected to all neurons\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam # build and compile a neural network model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#generating batches of augmented image data,which is commonly used for training deep learning models.\n",
        "# particularly for computer vision tasks like image classification and object detection.\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7__9bmQrpmBv"
      },
      "outputs": [],
      "source": [
        "# unzip the dataset\n",
        "!unzip -uq \"/content/drive/MyDrive/face mask/archive1-220321-141335.zip\" -d \"/content/drive/MyDrive/face mask/archive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9pmAbU9ktCey",
        "outputId": "5d07e0b9-de5d-4148-f895-d9fe216a6efd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/face mask/archive/New Masks Dataset/Test/Non Mask'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#store each paths to corresponding variables for easy usage\n",
        "import os\n",
        "main_dir=\"/content/drive/MyDrive/face mask/archive/New Masks Dataset\"\n",
        "train_dir=os.path.join(main_dir,'Train')\n",
        "test_dir=os.path.join(main_dir,'Test')\n",
        "valid_dir=os.path.join(main_dir,'Validation')\n",
        "\n",
        "train_mask_dir=os.path.join(train_dir,'Mask')\n",
        "train_nomask_dir=os.path.join(train_dir,'Non Mask')\n",
        "test_mask_dir=os.path.join(test_dir,'Mask')\n",
        "test_nomask_dir=os.path.join(test_dir,'Non Mask')\n",
        "valid_mask_dir=os.path.join(valid_dir,'Mask')\n",
        "valid_nomask_dir=os.path.join(valid_dir,'Non Mask')\n",
        "\n",
        "valid_nomask_dir\n",
        "test_nomask_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDWNaFcvtChR",
        "outputId": "ed63d11e-2f83-46d9-a789-42e65e28d017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1.jpg',\n",
              " '10.jpg',\n",
              " '100.jpg',\n",
              " '101.jpg',\n",
              " '102.jpg',\n",
              " '104.jpg',\n",
              " '105.jpg',\n",
              " '106.jpg',\n",
              " '107.jpg']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#optional\n",
        "train_mask_names=os.listdir(train_mask_dir)\n",
        "train_nomask_names=os.listdir(train_nomask_dir)\n",
        "train_nomask_names[1:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb4yM4kHtCjh",
        "outputId": "0404c9c4-6eff-4674-fbd4-60b1804ee73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 600 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n",
            "Found 306 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_datagen= ImageDataGenerator(rescale=1.0/255, #brings the pixel values into the range of [0, 1]\n",
        "                                  zoom_range=0.2,\n",
        "                                  rotation_range=40,\n",
        "                                  horizontal_flip = True)\n",
        "test_datagen=ImageDataGenerator(rescale=1.0/255)\n",
        "validation_datagen=ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,\n",
        "                                                  target_size=(150,150),#(width,height)\n",
        "                                                  batch_size=32, #no of images in each batch\n",
        "                                                  class_mode='binary') #class_index\n",
        "test_generator=test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(150,150),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='binary')\n",
        "valid_generator=validation_datagen.flow_from_directory(valid_dir,\n",
        "                                                  target_size=(150,150),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='binary') #two types : binary,categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih9UZf9ftCm5",
        "outputId": "43b3c62a-37d9-4047-f661-0b5778079d35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Mask': 0, 'Non Mask': 1}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmVI0wgpKHDf",
        "outputId": "3c6ee64b-2811-4ad9-aa5f-b261da354f92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 150, 3)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator.image_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D229Jyp4KXiT",
        "outputId": "fd6ec718-2b0e-4c34-99eb-0083fa7df073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 150, 150, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 75, 75, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 75, 75, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 37, 37, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 37, 37, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 87616)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               22429952  \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,449,601\n",
            "Trainable params: 22,449,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model.add(Conv2D(32, (3, 3), padding='SAME', activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(64, (3, 3), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification, so using sigmoid activation\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o-ACs8MPfYb",
        "outputId": "fb21809f-2de0-4b42-e171-08ad6087476b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCtaRlSOQXKU",
        "outputId": "6c397699-056d-4890-cf3f-0dd709983f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "19/19 [==============================] - 65s 3s/step - loss: 1.0692 - accuracy: 0.5700 - val_loss: 0.6893 - val_accuracy: 0.6242\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.4852 - accuracy: 0.8150 - val_loss: 0.4475 - val_accuracy: 0.8529\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 66s 4s/step - loss: 0.3913 - accuracy: 0.8500 - val_loss: 0.4713 - val_accuracy: 0.8693\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 52s 3s/step - loss: 0.2914 - accuracy: 0.9033 - val_loss: 0.3744 - val_accuracy: 0.8954\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.2578 - accuracy: 0.9100 - val_loss: 0.3309 - val_accuracy: 0.8954\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 53s 3s/step - loss: 0.2436 - accuracy: 0.9150 - val_loss: 0.3474 - val_accuracy: 0.8987\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 62s 3s/step - loss: 0.2353 - accuracy: 0.9167 - val_loss: 0.2951 - val_accuracy: 0.9020\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 53s 3s/step - loss: 0.2352 - accuracy: 0.9183 - val_loss: 0.3043 - val_accuracy: 0.9020\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.2100 - accuracy: 0.9350 - val_loss: 0.2901 - val_accuracy: 0.8922\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 56s 3s/step - loss: 0.2256 - accuracy: 0.9233 - val_loss: 0.2881 - val_accuracy: 0.9248\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 53s 3s/step - loss: 0.1939 - accuracy: 0.9217 - val_loss: 0.2392 - val_accuracy: 0.9150\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 53s 3s/step - loss: 0.2261 - accuracy: 0.9050 - val_loss: 0.2603 - val_accuracy: 0.9085\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1866 - accuracy: 0.9383 - val_loss: 0.2525 - val_accuracy: 0.9052\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.2047 - accuracy: 0.9233 - val_loss: 0.2614 - val_accuracy: 0.8922\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 53s 3s/step - loss: 0.2026 - accuracy: 0.9250 - val_loss: 0.2609 - val_accuracy: 0.8987\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1847 - accuracy: 0.9367 - val_loss: 0.2340 - val_accuracy: 0.9118\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.2221 - accuracy: 0.9217 - val_loss: 0.2866 - val_accuracy: 0.8758\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 55s 3s/step - loss: 0.2036 - accuracy: 0.9217 - val_loss: 0.2460 - val_accuracy: 0.9085\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 62s 3s/step - loss: 0.2099 - accuracy: 0.9233 - val_loss: 0.2528 - val_accuracy: 0.9150\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 50s 3s/step - loss: 0.1740 - accuracy: 0.9417 - val_loss: 0.2193 - val_accuracy: 0.9183\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 53s 3s/step - loss: 0.1570 - accuracy: 0.9417 - val_loss: 0.2448 - val_accuracy: 0.8987\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1974 - accuracy: 0.9350 - val_loss: 0.2549 - val_accuracy: 0.9085\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1694 - accuracy: 0.9300 - val_loss: 0.2377 - val_accuracy: 0.9118\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1692 - accuracy: 0.9317 - val_loss: 0.2301 - val_accuracy: 0.9118\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.2129 - accuracy: 0.9217 - val_loss: 0.2969 - val_accuracy: 0.8987\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1923 - accuracy: 0.9350 - val_loss: 0.2209 - val_accuracy: 0.9248\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 52s 3s/step - loss: 0.1775 - accuracy: 0.9383 - val_loss: 0.2209 - val_accuracy: 0.9118\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1834 - accuracy: 0.9300 - val_loss: 0.2312 - val_accuracy: 0.9248\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.1642 - accuracy: 0.9400 - val_loss: 0.2263 - val_accuracy: 0.9150\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 52s 3s/step - loss: 0.1498 - accuracy: 0.9433 - val_loss: 0.2214 - val_accuracy: 0.9216\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_generator,\n",
        "                  epochs=30,\n",
        "                  validation_data = valid_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRdR2r-URF9f",
        "outputId": "83f5f7c8-d580-4735-f596-63297a747dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 583ms/step - loss: 1.1381 - accuracy: 0.5000\n",
            "test acc :0.5 test loss : 1.1380717754364014\n"
          ]
        }
      ],
      "source": [
        "test_loss,test_acc=model.evaluate(test_generator)\n",
        "print('test acc :{} test loss : {}'.format(test_acc,test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsDoD8VEZekV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "for f in uploaded.keys():\n",
        "  image_path='/content'+f\n",
        "  img=image.load_img(image_path,target_size=(150,150))\n",
        "  images=image.img_to_array(img)\n",
        "  #images=np.expand_dims(images,axis=0)\n",
        "  prediction=model.predict(images)\n",
        "  if(prediction==0):\n",
        "    print(f,\"mask is there\")\n",
        "  else:\n",
        "    print(f,\"no mask is present\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "YBRArWiMbggY",
        "outputId": "2bde6964-f0c1-41e7-8619-19e6aed294c9"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-5a5ae40ae856>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming 'model' is already defined and loaded with your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_img' from 'keras.preprocessing.image' (/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "# Assuming 'model' is already defined and loaded with your trained model\n",
        "\n",
        "uploaded = files.upload()\n",
        "for f in uploaded.keys():\n",
        "    image_path = '/content/' + f\n",
        "    img = image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)  # Changed 'images' to 'img_array'\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Expanding dimensions\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    if prediction == 0:\n",
        "        print(f, \"mask is there\")\n",
        "    else:\n",
        "        print(f, \"no mask is present\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_aYBALIa8qG"
      },
      "outputs": [],
      "source": [
        "model.save('saved_model07.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}